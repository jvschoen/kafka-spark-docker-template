{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to utilize Spark in a cluster environment You need to first spin up a cluster and then attach a notebook to the cluster instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "from configparser import ConfigParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROFILE_ID='default'\n",
    "config_object = ConfigParser()\n",
    "config_object.read(\"/home/jovyan/.aws/credentials\")\n",
    "profile_info = config_object[PROFILE_ID]\n",
    "\n",
    "ACCESS_KEY = profile_info.get('aws_access_key_id')\n",
    "SECRET_KEY = profile_info.get('aws_secret_access_key')\n",
    "AWS_SESSION_TOKEN = profile_info.get('aws_session_token')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_NAME=\"jvs-fraud\"\n",
    "LOG_URI=f\"s3://aws-logs-119657064844-us-east-1/\"\n",
    "RELEASE_LABEL=\"emr-5.32.0\" # Max version for use with Notebooks\n",
    "NUM_CORE_NODES=6\n",
    "NUM_INSTANCES=1 + NUM_CORE_NODES # 1 Master + N slaves\n",
    "\n",
    "# Must use AMD EPYC instances ie m5a.*\n",
    "INSTANCE_TYPE=\"m5a.xlarge\"  # $0.172/hr 4core-16GB RAM\n",
    "\n",
    "EC2_KEY=\"jvs_ec2_key\"\n",
    "EC2_SUBNET=\"subnet-171c8c4b\"\n",
    "REGION=\"us-east-1\"\n",
    "\n",
    "# This is where we want our notebook data to persist\n",
    "BUCKET_NAME=\"jvs-fraud-research\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create EMR Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create EC2 Key Pair and PEM File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Go to [Amazon EC2 console](https://console.aws.amazon.com/ec2/home)\n",
    "2. click Key Pairs\n",
    "3. Create Key Pairs\n",
    "4. Make a name\n",
    "5. Save PEM file locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using AWS CLI\n",
    "If you prefer starting the cluster with AWS CLI, set the USE_CLI constant to true below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CLI=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the CLI command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_CLI:\n",
    "    make_cluster_cmd = f\"\"\"\n",
    "        aws emr create-cluster \\\\\n",
    "        --release-label {RELEASE_LABEL} \\\\\n",
    "        --applications Name=Spark \\\\\n",
    "        --instance-type {INSTANCE_TYPE} \\\\\n",
    "        --instance-count {NUM_INSTANCES} \\\\\n",
    "        --name {CLUSTER_NAME} \\\\\n",
    "        --log-uri s3://aws-logs-{CLUSTER_NAME}/elasticmapreduce/ \\\\\n",
    "        --use-default-roles \\\\\n",
    "        --ec2-attributes KeyName={EC2_KEY},SubnetId={EC2_SUBNET} \\\\\n",
    "        --region {REGION}\n",
    "    \"\"\"\n",
    "    print(make_cluster_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the command and **create the cluster**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_CLI:\n",
    "    !{make_cluster_cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminate Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the Cluster ID above and input to the cell below to run the command and **terminate the cluster**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_id = \"j-3GTMZ6TB4TEEM\"\n",
    "if USE_CLI:\n",
    "    !aws emr terminate-clusters --cluster-ids {cluster_id} --region us-east-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USING Python - boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Bucket\n",
    "Only creates bucket if doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=ACCESS_KEY,\n",
    "    aws_secret_access_key=SECRET_KEY,\n",
    "    aws_session_token=AWS_SESSION_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the bucket if doesn't exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket s3://jvs-fraud-research exists\n"
     ]
    }
   ],
   "source": [
    "if BUCKET_NAME not in [val['Name'] for val in s3.list_buckets()['Buckets']]:\n",
    "    s3.create_bucket(Bucket=BUCKET_NAME)\n",
    "else:\n",
    "    print(f'Bucket s3://{BUCKET_NAME} exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/26314316/how-to-launch-and-configure-an-emr-cluster-using-boto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMR ID: j-3QXDA47I2Y20B\n"
     ]
    }
   ],
   "source": [
    "emr = boto3.client('emr', region_name=REGION)\n",
    "\n",
    "response = emr.run_job_flow(\n",
    "    Name=CLUSTER_NAME,\n",
    "    LogUri=LOG_URI,\n",
    "    ReleaseLabel=RELEASE_LABEL,\n",
    "    Instances={\n",
    "        'MasterInstanceType': INSTANCE_TYPE,\n",
    "        'SlaveInstanceType': INSTANCE_TYPE,\n",
    "        'InstanceCount': NUM_INSTANCES,\n",
    "        'KeepJobFlowAliveWhenNoSteps': True,\n",
    "        'TerminationProtected': False,\n",
    "        'Ec2KeyName': EC2_KEY,\n",
    "        'Ec2SubnetId': EC2_SUBNET\n",
    "    },\n",
    "    Applications=[\n",
    "        {'Name': 'Spark'},\n",
    "        {'Name': 'Hadoop'},\n",
    "        {'Name': 'Livy'},\n",
    "        {'Name': 'JupyterEnterpriseGateway'}\n",
    "    ],\n",
    "    VisibleToAllUsers=True,\n",
    "    JobFlowRole='EMR_EC2_DefaultRole',\n",
    "    ServiceRole='EMR_DefaultRole'\n",
    "    \n",
    ")\n",
    "print(f\"EMR ID: {response['JobFlowId']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the EMR is stood up you can go to the [EMR Notebooks Page](https://console.aws.amazon.com/elasticmapreduce/home?region=us-east-1#notebooks-list:) To create (or open) a notebook to work from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminate Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'b02a5a98-824c-4290-9915-2e1bbdd7431d',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'b02a5a98-824c-4290-9915-2e1bbdd7431d',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Fri, 18 Dec 2020 22:59:44 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emr.terminate_job_flows(JobFlowIds=[response['JobFlowId']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/getting-started-with-pyspark-on-amazon-emr-c85154b6b921"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EMR Notebook Magic\n",
    "```\n",
    "%%configure -f\n",
    "{\"executorMemory\":\"4G\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
